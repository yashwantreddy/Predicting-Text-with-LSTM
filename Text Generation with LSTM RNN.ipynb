{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Downloads/alice-in-wonderland.txt\"\n",
    "raw_text = open(filename,encoding='utf8').read()\n",
    "raw_text = raw_text.lower()\n",
    "raw_text = raw_text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffchapter i. down the rabbit-hole  alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‘and what is the use of a book,’ thought alice ‘without pictures or conversations?’  so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '(': 2,\n",
       " ')': 3,\n",
       " '*': 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '?': 10,\n",
       " '[': 11,\n",
       " ']': 12,\n",
       " '_': 13,\n",
       " 'a': 14,\n",
       " 'b': 15,\n",
       " 'c': 16,\n",
       " 'd': 17,\n",
       " 'e': 18,\n",
       " 'f': 19,\n",
       " 'g': 20,\n",
       " 'h': 21,\n",
       " 'i': 22,\n",
       " 'j': 23,\n",
       " 'k': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'q': 30,\n",
       " 'r': 31,\n",
       " 's': 32,\n",
       " 't': 33,\n",
       " 'u': 34,\n",
       " 'v': 35,\n",
       " 'w': 36,\n",
       " 'x': 37,\n",
       " 'y': 38,\n",
       " 'z': 39,\n",
       " '‘': 40,\n",
       " '’': 41,\n",
       " '“': 42,\n",
       " '”': 43,\n",
       " '\\ufeff': 44}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144348\n",
      "Total Vocab:  45\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144248\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144248, 100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144248, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 2.9290Epoch 00001: loss improved from inf to 2.92887, saving model to weights-improvement-01-2.9289.hdf5\n",
      "144248/144248 [==============================] - 2363s 16ms/step - loss: 2.9289\n",
      "Epoch 2/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 2.7372Epoch 00002: loss improved from 2.92887 to 2.73725, saving model to weights-improvement-02-2.7373.hdf5\n",
      "144248/144248 [==============================] - 2394s 17ms/step - loss: 2.7373\n",
      "Epoch 3/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 2.6347Epoch 00003: loss improved from 2.73725 to 2.63463, saving model to weights-improvement-03-2.6346.hdf5\n",
      "144248/144248 [==============================] - 2404s 17ms/step - loss: 2.6346\n",
      "Epoch 4/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.5596Epoch 00004: loss improved from 2.63463 to 2.55964, saving model to weights-improvement-04-2.5596.hdf5\n",
      "144248/144248 [==============================] - 2416s 17ms/step - loss: 2.5596\n",
      "Epoch 5/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.4922Epoch 00005: loss improved from 2.55964 to 2.49213, saving model to weights-improvement-05-2.4921.hdf5\n",
      "144248/144248 [==============================] - 2430s 17ms/step - loss: 2.4921\n",
      "Epoch 6/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.4277Epoch 00006: loss improved from 2.49213 to 2.42736, saving model to weights-improvement-06-2.4274.hdf5\n",
      "144248/144248 [==============================] - 2462s 17ms/step - loss: 2.4274\n",
      "Epoch 7/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.3728Epoch 00007: loss improved from 2.42736 to 2.37284, saving model to weights-improvement-07-2.3728.hdf5\n",
      "144248/144248 [==============================] - 2428s 17ms/step - loss: 2.3728\n",
      "Epoch 8/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.3188Epoch 00008: loss improved from 2.37284 to 2.31888, saving model to weights-improvement-08-2.3189.hdf5\n",
      "144248/144248 [==============================] - 2454s 17ms/step - loss: 2.3189\n",
      "Epoch 9/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.2693Epoch 00009: loss improved from 2.31888 to 2.26925, saving model to weights-improvement-09-2.2693.hdf5\n",
      "144248/144248 [==============================] - 2429s 17ms/step - loss: 2.2693\n",
      "Epoch 10/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.2227Epoch 00010: loss improved from 2.26925 to 2.22250, saving model to weights-improvement-10-2.2225.hdf5\n",
      "144248/144248 [==============================] - 2468s 17ms/step - loss: 2.2225\n",
      "Epoch 11/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.1778Epoch 00011: loss improved from 2.22250 to 2.17788, saving model to weights-improvement-11-2.1779.hdf5\n",
      "144248/144248 [==============================] - 2447s 17ms/step - loss: 2.1779\n",
      "Epoch 12/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.1337Epoch 00012: loss improved from 2.17788 to 2.13364, saving model to weights-improvement-12-2.1336.hdf5\n",
      "144248/144248 [==============================] - 2412s 17ms/step - loss: 2.1336\n",
      "Epoch 13/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 2.0911Epoch 00013: loss improved from 2.13364 to 2.09124, saving model to weights-improvement-13-2.0912.hdf5\n",
      "144248/144248 [==============================] - 2368s 16ms/step - loss: 2.0912\n",
      "Epoch 14/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.0500Epoch 00014: loss improved from 2.09124 to 2.04985, saving model to weights-improvement-14-2.0498.hdf5\n",
      "144248/144248 [==============================] - 2460s 17ms/step - loss: 2.0498\n",
      "Epoch 15/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 2.0144Epoch 00015: loss improved from 2.04985 to 2.01433, saving model to weights-improvement-15-2.0143.hdf5\n",
      "144248/144248 [==============================] - 2501s 17ms/step - loss: 2.0143\n",
      "Epoch 16/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 1.9778Epoch 00016: loss improved from 2.01433 to 1.97761, saving model to weights-improvement-16-1.9776.hdf5\n",
      "144248/144248 [==============================] - 2507s 17ms/step - loss: 1.9776\n",
      "Epoch 17/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 1.9460Epoch 00017: loss improved from 1.97761 to 1.94583, saving model to weights-improvement-17-1.9458.hdf5\n",
      "144248/144248 [==============================] - 2417s 17ms/step - loss: 1.9458\n",
      "Epoch 18/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 1.9115Epoch 00018: loss improved from 1.94583 to 1.91154, saving model to weights-improvement-18-1.9115.hdf5\n",
      "144248/144248 [==============================] - 2390s 17ms/step - loss: 1.9115\n",
      "Epoch 19/20\n",
      "144128/144248 [============================>.] - ETA: 2s - loss: 1.8836Epoch 00019: loss improved from 1.91154 to 1.88373, saving model to weights-improvement-19-1.8837.hdf5\n",
      "144248/144248 [==============================] - 2431s 17ms/step - loss: 1.8837\n",
      "Epoch 20/20\n",
      "144128/144248 [============================>.] - ETA: 1s - loss: 1.8576Epoch 00020: loss improved from 1.88373 to 1.85749, saving model to weights-improvement-20-1.8575.hdf5\n",
      "144248/144248 [==============================] - 2353s 16ms/step - loss: 1.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264e72fec18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffchapter i. down the rabbit-hole  alice was beginning to get very tired of sitting by her sister on '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ally see shakespeare, in the pictures of him), while the rest waited in silence. at last the dodo sa \"\n",
      "ld, ‘it was a latter of the soeerers,’  ‘ie ion’t tie kine an thlleng’t tone,’ said alice, an at oncee at the could, and whs gerting to an  lh the dour oe the court,  nie had aeen ennnid on the sase an in white was toe tithle thet was a lirtle soinei  the was a lirtle soine to bn the woode  and the was a lirtle soine to bn the woode  she was a lirtle soine to be and then th the whyh the was a lirtle so tat anong the taade  the coum on the tase wire tiee   ‘he inr toe was at il ’hu it as i sas io a fott ’eth she boore!’  ‘ho whet would ’ou goon the dan’t ’hu would ’ou coold,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar.  ‘you mave you moen,’ said the caterpillar. \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
